{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I like the item pricing. My granddaughter want...</td>\n",
       "      <td>01 29, 2014</td>\n",
       "      <td>A1VXOAVRGKGEAK</td>\n",
       "      <td>Angie</td>\n",
       "      <td>Magnetic board</td>\n",
       "      <td>1390953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>Love the magnet easel... great for moving to d...</td>\n",
       "      <td>03 28, 2014</td>\n",
       "      <td>A8R62G708TSCM</td>\n",
       "      <td>Candace</td>\n",
       "      <td>it works pretty good for moving to different a...</td>\n",
       "      <td>1395964800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Both sides are magnetic.  A real plus when you...</td>\n",
       "      <td>01 28, 2013</td>\n",
       "      <td>A21KH420DK0ICA</td>\n",
       "      <td>capemaychristy</td>\n",
       "      <td>love this!</td>\n",
       "      <td>1359331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Bought one a few years ago for my daughter and...</td>\n",
       "      <td>02 8, 2014</td>\n",
       "      <td>AR29QK6HPFYZ4</td>\n",
       "      <td>dcrm</td>\n",
       "      <td>Daughters love it</td>\n",
       "      <td>1391817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I have a stainless steel refrigerator therefor...</td>\n",
       "      <td>05 5, 2014</td>\n",
       "      <td>ACCH8EOML6FN5</td>\n",
       "      <td>DoyZ</td>\n",
       "      <td>Great to have so he can play with his alphabet...</td>\n",
       "      <td>1399248000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  0439893577  [0, 0]        5   \n",
       "1  0439893577  [1, 1]        4   \n",
       "2  0439893577  [1, 1]        5   \n",
       "3  0439893577  [0, 0]        5   \n",
       "4  0439893577  [1, 1]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I like the item pricing. My granddaughter want...  01 29, 2014   \n",
       "1  Love the magnet easel... great for moving to d...  03 28, 2014   \n",
       "2  Both sides are magnetic.  A real plus when you...  01 28, 2013   \n",
       "3  Bought one a few years ago for my daughter and...   02 8, 2014   \n",
       "4  I have a stainless steel refrigerator therefor...   05 5, 2014   \n",
       "\n",
       "       reviewerID    reviewerName  \\\n",
       "0  A1VXOAVRGKGEAK           Angie   \n",
       "1   A8R62G708TSCM         Candace   \n",
       "2  A21KH420DK0ICA  capemaychristy   \n",
       "3   AR29QK6HPFYZ4            dcrm   \n",
       "4   ACCH8EOML6FN5            DoyZ   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0                                     Magnetic board      1390953600  \n",
       "1  it works pretty good for moving to different a...      1395964800  \n",
       "2                                         love this!      1359331200  \n",
       "3                                  Daughters love it      1391817600  \n",
       "4  Great to have so he can play with his alphabet...      1399248000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#amz = pd.read_csv('ratings_CDs_and_Vinyl.csv')\n",
    "amz = pd.read_json('reviews_Toys_and_Games_5.json', lines=True)\n",
    "\n",
    "amz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.hist(amz.overall, color='#7F44F7')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most reviews are 5 star, the least reviews are 1 star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 0]\n",
       "1    [1, 1]\n",
       "2    [1, 1]\n",
       "3    [0, 0]\n",
       "4    [1, 1]\n",
       "Name: helpful, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz.helpful.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful_amt</th>\n",
       "      <th>helpful_tot</th>\n",
       "      <th>helpful_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   helpful_amt  helpful_tot  helpful_per\n",
       "0            0            0          0.0\n",
       "1            1            1          1.0\n",
       "2            1            1          1.0\n",
       "3            0            0          0.0\n",
       "4            1            1          1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpfuls = amz.helpful.apply(pd.Series)\n",
    "helpfuls.columns = ['helpful_amt','helpful_tot']\n",
    "helpfuls['helpful_per'] = helpfuls['helpful_amt']/helpfuls['helpful_tot']\n",
    "helpfuls['helpful_per']= helpfuls['helpful_per'].fillna(value=0)\n",
    "helpfuls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_amt</th>\n",
       "      <th>helpful_tot</th>\n",
       "      <th>helpful_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I like the item pricing. My granddaughter want...</td>\n",
       "      <td>01 29, 2014</td>\n",
       "      <td>A1VXOAVRGKGEAK</td>\n",
       "      <td>Angie</td>\n",
       "      <td>Magnetic board</td>\n",
       "      <td>1390953600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>Love the magnet easel... great for moving to d...</td>\n",
       "      <td>03 28, 2014</td>\n",
       "      <td>A8R62G708TSCM</td>\n",
       "      <td>Candace</td>\n",
       "      <td>it works pretty good for moving to different a...</td>\n",
       "      <td>1395964800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  0439893577  [0, 0]        5   \n",
       "1  0439893577  [1, 1]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I like the item pricing. My granddaughter want...  01 29, 2014   \n",
       "1  Love the magnet easel... great for moving to d...  03 28, 2014   \n",
       "\n",
       "       reviewerID reviewerName  \\\n",
       "0  A1VXOAVRGKGEAK        Angie   \n",
       "1   A8R62G708TSCM      Candace   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                     Magnetic board      1390953600   \n",
       "1  it works pretty good for moving to different a...      1395964800   \n",
       "\n",
       "   helpful_amt  helpful_tot  helpful_per  \n",
       "0            0            0          0.0  \n",
       "1            1            1          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz = pd.concat([amz[:], helpfuls[:]], axis=1)\n",
    "\n",
    "amz.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(amz.helpful_per, color='#7F44F7')\n",
    "plt.title('Helpful Percentage – Normal Scale')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('helpful percentage')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(amz.helpful_per, color='#7F44F7')\n",
    "plt.yscale('log')\n",
    "plt.title('Helpful Percentage – Log Scaled')\n",
    "plt.ylabel('count - log scaled')\n",
    "plt.xlabel('helpful percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "help_z = amz.loc[(amz.helpful_amt == 0)&(amz.helpful_tot>0)]\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(help_z.helpful_tot, color='#7F44F7')\n",
    "plt.title('Total Votes Above 0 – Normal Scale')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('Amount of Total Votes')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(help_z.helpful_tot, color='#7F44F7')\n",
    "plt.yscale('log')\n",
    "plt.title('Total Votes Above 0 – Log Scaled')\n",
    "plt.ylabel('count - log scaled')\n",
    "plt.xlabel('Amount of Total Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "- Most reviews, no one has clicked on if they are helful or not\n",
    "- Judging by the second most being 100%, I would also venture to say that most reviews have just one vote of if they are helpful or not.\n",
    "- The third highest percentage being 50% also supports the idea that most do not have that many votes.\n",
    "- Their being higher percentages in the upper half of the graph, shows that when people do vote, they tend to vote more positively then negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    167597.000000\n",
       "mean          0.275086\n",
       "std           0.418838\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.666667\n",
       "max           1.000000\n",
       "Name: helpful_per, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz.helpful_per.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102790.0</td>\n",
       "      <td>64807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           five      not\n",
       "count  102790.0  64807.0\n",
       "mean        1.0      0.0\n",
       "std         0.0      0.0\n",
       "min         1.0      0.0\n",
       "25%         1.0      0.0\n",
       "50%         1.0      0.0\n",
       "75%         1.0      0.0\n",
       "max         1.0      0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz['five_star'] = np.where(amz['overall']==5,1,0)\n",
    "compare = pd.DataFrame()\n",
    "\n",
    "compare['five'] = amz.five_star.loc[amz.five_star==1].describe()\n",
    "compare['not'] = amz.five_star.loc[amz.five_star==0].describe()\n",
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there is a slight imbalance in the data, to get an accurate prediction we'll take 50,000 rows from both the five-star reviews and also the non-five-star reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          five      not\n",
       "count  50000.0  50000.0\n",
       "mean       1.0      0.0\n",
       "std        0.0      0.0\n",
       "min        1.0      0.0\n",
       "25%        1.0      0.0\n",
       "50%        1.0      0.0\n",
       "75%        1.0      0.0\n",
       "max        1.0      0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_s = amz.sample(frac=1, random_state=40)\n",
    "\n",
    "fivestar = amz_s.loc[amz_s.five_star==1][:50000]\n",
    "nofive = amz_s.loc[amz_s.five_star==0][:50000]\n",
    "\n",
    "amz = pd.concat([fivestar, nofive])\n",
    "amz = amz.sample(frac=1, random_state=40)\n",
    "\n",
    "compare['five'] = amz.five_star.loc[amz.five_star==1].describe()\n",
    "compare['not'] = amz.five_star.loc[amz.five_star==0].describe()\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#five_star = text_cleaner(five_star)\n",
    "amz.reviewText = amz.reviewText.apply(lambda x: re.sub(r'--',' ',x))\n",
    "amz.reviewText = amz.reviewText.apply(lambda x: re.sub(\"[\\[].*?[\\]]\", \"\", x))\n",
    "amz.reviewText = amz.reviewText.apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [22:09<00:00, 75.22it/s] \n"
     ]
    }
   ],
   "source": [
    "# how long it will take and hopefully speed some stuff up\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en', disable=['ner', 'tagger'])\n",
    "# add parsed reviews into new column\n",
    "amz['review_parsed'] = amz.reviewText.progress_apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a sample of 10,000 rows we will find the most common words in 5 star reviews\n",
    "\n",
    "review_w_1 = ' '.join(amz.review_parsed.loc[amz.overall == 5][0:1000].astype(str))\n",
    "review_doc_1 = nlp(review_w_1)\n",
    "\n",
    "review_w_2 = ' '.join(amz.review_parsed.loc[amz.overall == 5][1001:2000].astype(str))\n",
    "review_doc_2 = nlp(review_w_2)\n",
    "\n",
    "review_w_3 = ' '.join(amz.review_parsed.loc[amz.overall == 5][2001:3000].astype(str))\n",
    "review_doc_3 = nlp(review_w_3)\n",
    "\n",
    "review_w_4 = ' '.join(amz.review_parsed.loc[amz.overall == 5][3001:5000].astype(str))\n",
    "review_doc_4 = nlp(review_w_4)\n",
    "\n",
    "review_w_5 = ' '.join(amz.review_parsed.loc[amz.overall == 5][4001:5000].astype(str))\n",
    "review_doc_5 = nlp(review_w_5)\n",
    "\n",
    "review_w_6 = ' '.join(amz.review_parsed.loc[amz.overall == 5][5001:6000].astype(str))\n",
    "review_doc_6 = nlp(review_w_6)\n",
    "\n",
    "review_w_7 = ' '.join(amz.review_parsed.loc[amz.overall == 5][6001:7000].astype(str))\n",
    "review_doc_7 = nlp(review_w_7)\n",
    "\n",
    "review_w_8 = ' '.join(amz.review_parsed.loc[amz.overall == 5][7001:8000].astype(str))\n",
    "review_doc_8 = nlp(review_w_8)\n",
    "\n",
    "review_w_9 = ' '.join(amz.review_parsed.loc[amz.overall == 5][8001:9000].astype(str))\n",
    "review_doc_9 = nlp(review_w_9)\n",
    "\n",
    "review_w_10 = ' '.join(amz.review_parsed.loc[amz.overall == 5][9001:10000].astype(str))\n",
    "review_doc_10 = nlp(review_w_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz = amz.drop(columns=['asin','reviewTime', 'reviewerID', 'reviewerName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_amt</th>\n",
       "      <th>helpful_tot</th>\n",
       "      <th>helpful_per</th>\n",
       "      <th>five_star</th>\n",
       "      <th>review_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>My son has a castle that he loves and when his...</td>\n",
       "      <td>Wish I had never purchased</td>\n",
       "      <td>1355961600</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(My, son, has, a, castle, that, he, loves, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>My 18 month old loves this phone! It was a gre...</td>\n",
       "      <td>Great phone!</td>\n",
       "      <td>1068422400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(My, 18, month, old, loves, this, phone, !, It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>I read some reviews complaining about the smel...</td>\n",
       "      <td>The smell is unbearable</td>\n",
       "      <td>1401667200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, read, some, reviews, complaining, about, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is my second one of these and it istill g...</td>\n",
       "      <td>nice</td>\n",
       "      <td>1404086400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(This, is, my, second, one, of, these, and, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this for my daughter. We never knew w...</td>\n",
       "      <td>pretty neat!</td>\n",
       "      <td>1384214400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(I, bought, this, for, my, daughter, ., We, ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  helpful  overall                                         reviewText  \\\n",
       "0  [2, 2]        2  My son has a castle that he loves and when his...   \n",
       "1  [0, 0]        5  My 18 month old loves this phone! It was a gre...   \n",
       "2  [1, 1]        1  I read some reviews complaining about the smel...   \n",
       "3  [0, 0]        5  This is my second one of these and it istill g...   \n",
       "4  [0, 0]        5  I bought this for my daughter. We never knew w...   \n",
       "\n",
       "                      summary  unixReviewTime  helpful_amt  helpful_tot  \\\n",
       "0  Wish I had never purchased      1355961600            2            2   \n",
       "1                Great phone!      1068422400            0            0   \n",
       "2     The smell is unbearable      1401667200            1            1   \n",
       "3                        nice      1404086400            0            0   \n",
       "4                pretty neat!      1384214400            0            0   \n",
       "\n",
       "   helpful_per  five_star                                      review_parsed  \n",
       "0          1.0          0  (My, son, has, a, castle, that, he, loves, and...  \n",
       "1          0.0          1  (My, 18, month, old, loves, this, phone, !, It...  \n",
       "2          1.0          0  (I, read, some, reviews, complaining, about, t...  \n",
       "3          0.0          1  (This, is, my, second, one, of, these, and, it...  \n",
       "4          0.0          1  (I, bought, this, for, my, daughter, ., We, ne...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz = amz.reset_index(drop=True)\n",
    "amz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 200 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(200)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(amz, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = amz['review_parsed']\n",
    "    df['rating'] = amz['overall']\n",
    "    df['five_star'] = amz['five_star']\n",
    "    df['unixReviewTime'] = amz['unixReviewTime']\n",
    "    df['helpful_amt'] = amz['helpful_amt']\n",
    "    df['helpful_tot'] = amz['helpful_tot']\n",
    "    df['helpful_per'] = amz['helpful_per']\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 5000 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "#common_words = bag_of_words(review_doc)\n",
    "#print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "source": [
    "common_words_1 = bag_of_words(review_doc_1)\n",
    "common_words_2 = bag_of_words(review_doc_2)\n",
    "common_words_3 = bag_of_words(review_doc_3)\n",
    "common_words_4 = bag_of_words(review_doc_4)\n",
    "common_words_5 = bag_of_words(review_doc_5)\n",
    "common_words_6 = bag_of_words(review_doc_6)\n",
    "common_words_7 = bag_of_words(review_doc_7)\n",
    "common_words_8 = bag_of_words(review_doc_8)\n",
    "common_words_9 = bag_of_words(review_doc_9)\n",
    "common_words_10 = bag_of_words(review_doc_10)\n",
    "common_words = (common_words_1+common_words_2+common_words_1+common_words_3+common_words_4+common_words_5\n",
    "               +common_words_6+common_words_7+common_words_8+common_words_9+common_words_10)\n",
    "common_words = list(set(common_words))\n",
    "print(len(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['break', 'able', 'baby', 'camera', 'nice', 'use', 'look', 'battery', 'happy', 'tell', 'money', 'friend', '8', 'get', 'read', 'My', 'year', 'child', 'fit', 'As', 'big', 'product', 'etc', 'awesome', 'fly', 'head', 'fact', 'need', 'high', 'pretty', 'Thomas', 'yr', 'definitely', 'push', 'door', 'bite', '5', 'size', 'mean', 'color', 'pack', 'away', 'worth', 'handle', 'know', 'store', 'A', '10', 'animal', 'feature', '1', 'different', 'Christmas', 'let', 'fan', 'picture', 'granddaughter', 'For', 'truck', 'sturdy', 'especially', 'fast', 'food', 'will', 'age', 'hour', 'line', 'helicopter', 'perfect', 'simple', 'educational', 'We', 'fun', 'problem', 'letter', 'But', 'idea', 'hard', 'turn', 'work', 'ask', 'Lego', 'They', 'rule', '2', 'favorite', 'challenge', 'old', 'action', 'like', 'She', 'race', 'one', 'add', 'Doug', 'Very', 'All', 'stick', 'day', 'sure', 'sit', 'have', 'teach', 'blue', '-PRON-', 'light', 'The', 'And', 'original', 'book', 'purchase', 'play', 'house', 'shape', 'paint', 'button', 'ball', 'piece', 'allow', 'close', 'watch', 'Our', 'hold', 'make', 'help', 'point', 'mode', 'would', 'new', 'kit', 'thing', 'match', 'come', 'In', 'kid', 'highly', '$', 'pick', 'fall', 'He', 'keep', 'absolutely', 'find', 'son', 'easily', 'enjoy', 'see', 'This', 'design', '6', 'addition', 'cute', 'go', 'So', 'run', 'music', 'hair', 'block', 'hand', 'open', 'room', 'way', 'gun', 'set', 'little', 'month', 'gift', 'great', 'collection', 'track', 'bag', 'word', 'eye', '3', 'player', 'You', 'be', 'boy', 'change', 'far', 'When', 'buy', 'girl', 'water', 'plastic', 'take', 'price', '7', 'win', 'card', 'time', 'stuff', 'hit', 'long', 'not', 'stand', 'doll', 'try', 'toddler', 'stay', 'item', 'easy', 'star', 'include', 'game', 'lot', 'sound', 'car', 'minute', 'give', 'character', 'face', 'super', 'puzzle', 'train', 'say', 'receive', 'It', 'leave', 'think', 'love', 'quickly', 'pink', 'parent', 'family', 'vehicle', 'people', 'real', 'soft', 'extra', 'adult', 'dart', 'learn', 'recommend', 'These', 'package', 'well', 'start', 'detail', 'case', 'box', 'Great', 'kitchen', 'quality', 'grandson', 'value', 'There', 'end', 'daughter', 'durable', 'feel', 'young', 'review', 'table', 'figure', 'party', 'pull', 'Her', 'ship', 'expansion', 'good', 'probably', 'cool', 'place', 'actually', 'Amazon', 'inside', 'build', 'small', 'cube', '4', 'want', 'If', 'order', 'interest', 'version', 'lose', 'nephew', 'large', 'toy', 'birthday', 'right', 'part', 'roll', 'board', 'rotate', 'I']\n"
     ]
    }
   ],
   "source": [
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 5000\n",
      "Processing row 10000\n",
      "Processing row 15000\n",
      "Processing row 20000\n",
      "Processing row 25000\n",
      "Processing row 30000\n",
      "Processing row 35000\n",
      "Processing row 40000\n",
      "Processing row 45000\n",
      "Processing row 50000\n",
      "Processing row 55000\n",
      "Processing row 60000\n",
      "Processing row 65000\n",
      "Processing row 70000\n",
      "Processing row 75000\n",
      "Processing row 80000\n",
      "Processing row 85000\n",
      "Processing row 90000\n",
      "Processing row 95000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>break</th>\n",
       "      <th>able</th>\n",
       "      <th>baby</th>\n",
       "      <th>camera</th>\n",
       "      <th>nice</th>\n",
       "      <th>use</th>\n",
       "      <th>look</th>\n",
       "      <th>battery</th>\n",
       "      <th>happy</th>\n",
       "      <th>tell</th>\n",
       "      <th>...</th>\n",
       "      <th>board</th>\n",
       "      <th>rotate</th>\n",
       "      <th>I</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>rating</th>\n",
       "      <th>five_star</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_amt</th>\n",
       "      <th>helpful_tot</th>\n",
       "      <th>helpful_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(My, son, has, a, castle, that, he, loves, and...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1355961600</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(My, 18, month, old, loves, this, phone, !, It...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1068422400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(I, read, some, reviews, complaining, about, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1401667200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(This, is, my, second, one, of, these, and, it...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1404086400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(I, bought, this, for, my, daughter, ., We, ne...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1384214400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   break  able  baby  camera  nice  use  look  battery  happy  tell  \\\n",
       "0      1     0     0       0     0    0     0        0      0     0   \n",
       "1      0     0     0       0     0    0     0        0      0     0   \n",
       "2      0     0     0       0     0    0     0        0      0     0   \n",
       "3      0     0     0       0     0    0     0        0      0     0   \n",
       "4      0     0     0       0     0    0     0        1      0     0   \n",
       "\n",
       "      ...       board  rotate  I  \\\n",
       "0     ...           0       0  4   \n",
       "1     ...           0       0  1   \n",
       "2     ...           0       0  2   \n",
       "3     ...           0       0  0   \n",
       "4     ...           0       0  1   \n",
       "\n",
       "                                       text_sentence  rating  five_star  \\\n",
       "0  (My, son, has, a, castle, that, he, loves, and...       2          0   \n",
       "1  (My, 18, month, old, loves, this, phone, !, It...       5          1   \n",
       "2  (I, read, some, reviews, complaining, about, t...       1          0   \n",
       "3  (This, is, my, second, one, of, these, and, it...       5          1   \n",
       "4  (I, bought, this, for, my, daughter, ., We, ne...       5          1   \n",
       "\n",
       "   unixReviewTime  helpful_amt  helpful_tot  helpful_per  \n",
       "0      1355961600            2            2          1.0  \n",
       "1      1068422400            0            0          0.0  \n",
       "2      1401667200            1            1          1.0  \n",
       "3      1404086400            0            0          0.0  \n",
       "4      1384214400            0            0          0.0  \n",
       "\n",
       "[5 rows x 294 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(amz, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>F Score</th>\n",
       "      <th>P Value</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>not</td>\n",
       "      <td>4290.780990</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>love</td>\n",
       "      <td>1959.389292</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>I</td>\n",
       "      <td>1821.516303</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>like</td>\n",
       "      <td>1742.886697</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The</td>\n",
       "      <td>1658.045719</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>think</td>\n",
       "      <td>1613.765448</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>star</td>\n",
       "      <td>1272.012461</td>\n",
       "      <td>7.587822e-277</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>try</td>\n",
       "      <td>1125.331661</td>\n",
       "      <td>2.401164e-245</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>But</td>\n",
       "      <td>1086.560112</td>\n",
       "      <td>5.187746e-237</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>work</td>\n",
       "      <td>1072.411814</td>\n",
       "      <td>5.717971e-234</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>have</td>\n",
       "      <td>1068.599420</td>\n",
       "      <td>3.776488e-233</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>hard</td>\n",
       "      <td>1061.849595</td>\n",
       "      <td>1.068326e-231</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Great</td>\n",
       "      <td>1009.258713</td>\n",
       "      <td>2.200468e-220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bite</td>\n",
       "      <td>1004.650501</td>\n",
       "      <td>2.158646e-219</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pretty</td>\n",
       "      <td>948.183366</td>\n",
       "      <td>3.088225e-207</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>fall</td>\n",
       "      <td>945.030484</td>\n",
       "      <td>1.474495e-206</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>toy</td>\n",
       "      <td>939.811952</td>\n",
       "      <td>1.960839e-205</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>plastic</td>\n",
       "      <td>922.449768</td>\n",
       "      <td>1.076003e-201</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>small</td>\n",
       "      <td>850.947160</td>\n",
       "      <td>2.749592e-186</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>interest</td>\n",
       "      <td>801.746988</td>\n",
       "      <td>1.117334e-175</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>probably</td>\n",
       "      <td>689.212223</td>\n",
       "      <td>2.170129e-151</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>break</td>\n",
       "      <td>655.334133</td>\n",
       "      <td>4.515775e-144</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>good</td>\n",
       "      <td>644.665409</td>\n",
       "      <td>9.119797e-142</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>highly</td>\n",
       "      <td>627.999296</td>\n",
       "      <td>3.645321e-138</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-PRON-</td>\n",
       "      <td>619.946341</td>\n",
       "      <td>2.006066e-136</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>thing</td>\n",
       "      <td>617.099098</td>\n",
       "      <td>8.275717e-136</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>stay</td>\n",
       "      <td>599.601812</td>\n",
       "      <td>5.017716e-132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>would</td>\n",
       "      <td>587.555856</td>\n",
       "      <td>2.019217e-129</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>will</td>\n",
       "      <td>585.909419</td>\n",
       "      <td>4.583747e-129</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>If</td>\n",
       "      <td>584.873912</td>\n",
       "      <td>7.676267e-129</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>educational</td>\n",
       "      <td>13.968704</td>\n",
       "      <td>1.859825e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>letter</td>\n",
       "      <td>13.927477</td>\n",
       "      <td>1.901057e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>7</td>\n",
       "      <td>13.655867</td>\n",
       "      <td>2.196713e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>new</td>\n",
       "      <td>13.209274</td>\n",
       "      <td>2.787068e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>bag</td>\n",
       "      <td>12.764645</td>\n",
       "      <td>3.533985e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Lego</td>\n",
       "      <td>11.485259</td>\n",
       "      <td>7.017743e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>teach</td>\n",
       "      <td>11.049686</td>\n",
       "      <td>8.873409e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>character</td>\n",
       "      <td>10.928798</td>\n",
       "      <td>9.471420e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>yr</td>\n",
       "      <td>9.951773</td>\n",
       "      <td>1.607422e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>nephew</td>\n",
       "      <td>9.951221</td>\n",
       "      <td>1.607903e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>dart</td>\n",
       "      <td>9.538033</td>\n",
       "      <td>2.013124e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>9.534204</td>\n",
       "      <td>2.017328e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>expansion</td>\n",
       "      <td>9.360606</td>\n",
       "      <td>2.217575e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>face</td>\n",
       "      <td>9.227546</td>\n",
       "      <td>2.384624e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>add</td>\n",
       "      <td>8.502903</td>\n",
       "      <td>3.546590e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>win</td>\n",
       "      <td>8.336921</td>\n",
       "      <td>3.885571e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>party</td>\n",
       "      <td>7.381892</td>\n",
       "      <td>6.589517e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camera</td>\n",
       "      <td>7.192976</td>\n",
       "      <td>7.320150e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>match</td>\n",
       "      <td>6.759789</td>\n",
       "      <td>9.324849e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>This</td>\n",
       "      <td>6.719292</td>\n",
       "      <td>9.538935e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>shape</td>\n",
       "      <td>6.630635</td>\n",
       "      <td>1.002538e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>help</td>\n",
       "      <td>6.124039</td>\n",
       "      <td>1.333722e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>5.894194</td>\n",
       "      <td>1.519263e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>build</td>\n",
       "      <td>5.833187</td>\n",
       "      <td>1.572839e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>watch</td>\n",
       "      <td>5.813631</td>\n",
       "      <td>1.590422e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>rotate</td>\n",
       "      <td>5.613958</td>\n",
       "      <td>1.781986e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>5.564579</td>\n",
       "      <td>1.832933e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>animal</td>\n",
       "      <td>5.145001</td>\n",
       "      <td>2.331553e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>blue</td>\n",
       "      <td>4.486129</td>\n",
       "      <td>3.417343e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>hit</td>\n",
       "      <td>3.866003</td>\n",
       "      <td>4.927650e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Attribute      F Score        P Value  Support\n",
       "194          not  4290.780990   0.000000e+00     True\n",
       "220         love  1959.389292   0.000000e+00     True\n",
       "286            I  1821.516303   0.000000e+00     True\n",
       "89          like  1742.886697   0.000000e+00     True\n",
       "106          The  1658.045719   0.000000e+00     True\n",
       "219        think  1613.765448   0.000000e+00     True\n",
       "202         star  1272.012461  7.587822e-277     True\n",
       "197          try  1125.331661  2.401164e-245     True\n",
       "75           But  1086.560112  5.187746e-237     True\n",
       "79          work  1072.411814  5.717971e-234     True\n",
       "101         have  1068.599420  3.776488e-233     True\n",
       "77          hard  1061.849595  1.068326e-231     True\n",
       "241        Great  1009.258713  2.200468e-220     True\n",
       "35          bite  1004.650501  2.158646e-219     True\n",
       "29        pretty   948.183366  3.088225e-207     True\n",
       "138         fall   945.030484  1.474495e-206     True\n",
       "279          toy   939.811952  1.960839e-205     True\n",
       "184      plastic   922.449768  1.076003e-201     True\n",
       "268        small   850.947160  2.749592e-186     True\n",
       "274     interest   801.746988  1.117334e-175     True\n",
       "261     probably   689.212223  2.170129e-151     True\n",
       "0          break   655.334133  4.515775e-144     True\n",
       "260         good   644.665409  9.119797e-142     True\n",
       "135       highly   627.999296  3.645321e-138     True\n",
       "104       -PRON-   619.946341  2.006066e-136     True\n",
       "130        thing   617.099098  8.275717e-136     True\n",
       "199         stay   599.601812  5.017716e-132     True\n",
       "127        would   587.555856  2.019217e-129     True\n",
       "63          will   585.909419  4.583747e-129     True\n",
       "272           If   584.873912  7.676267e-129     True\n",
       "..           ...          ...            ...      ...\n",
       "70   educational    13.968704   1.859825e-04     True\n",
       "74        letter    13.927477   1.901057e-04     True\n",
       "187            7    13.655867   2.196713e-04     True\n",
       "128          new    13.209274   2.787068e-04     True\n",
       "170          bag    12.764645   3.533985e-04     True\n",
       "81          Lego    11.485259   7.017743e-04     True\n",
       "102        teach    11.049686   8.873409e-04     True\n",
       "210    character    10.928798   9.471420e-04     True\n",
       "31            yr     9.951773   1.607422e-03     True\n",
       "277       nephew     9.951221   1.607903e-03     True\n",
       "231         dart     9.538033   2.013124e-03     True\n",
       "30        Thomas     9.534204   2.017328e-03     True\n",
       "259    expansion     9.360606   2.217575e-03     True\n",
       "211         face     9.227546   2.384624e-03     True\n",
       "93           add     8.502903   3.546590e-03     True\n",
       "188          win     8.336921   3.885571e-03     True\n",
       "255        party     7.381892   6.589517e-03     True\n",
       "3         camera     7.192976   7.320150e-03     True\n",
       "131        match     6.759789   9.324849e-03     True\n",
       "147         This     6.719292   9.538935e-03     True\n",
       "113        shape     6.630635   1.002538e-02     True\n",
       "124         help     6.124039   1.333722e-02     True\n",
       "67    helicopter     5.894194   1.519263e-02     True\n",
       "267        build     5.833187   1.572839e-02     True\n",
       "120        watch     5.813631   1.590422e-02     True\n",
       "285       rotate     5.613958   1.781986e-02     True\n",
       "213       puzzle     5.564579   1.832933e-02     True\n",
       "48        animal     5.145001   2.331553e-02     True\n",
       "103         blue     4.486129   3.417343e-02     True\n",
       "192          hit     3.866003   4.927650e-02     True\n",
       "\n",
       "[271 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X = word_counts.drop(['five_star','rating','text_sentence'], 1)\n",
    "y = word_counts['five_star']\n",
    "\n",
    "selector=SelectKBest(score_func=f_classif,k=291)\n",
    "selector.fit(X,y)\n",
    "scores = pd.DataFrame()\n",
    "scores[\"Attribute\"] = X.columns\n",
    "scores[\"F Score\"] = selector.scores_\n",
    "scores[\"P Value\"] = selector.pvalues_\n",
    "scores[\"Support\"] = selector.get_support()\n",
    "\n",
    "scores = scores.sort_values(by=['F Score'], ascending=False)\n",
    "\n",
    "scores.loc[scores['P Value']<.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_vals = scores.Attribute.head(80).values\n",
    "\n",
    "key_vals = scores.Attribute.loc[scores['P Value']<.05].values\n",
    "\n",
    "X = word_counts[key_vals]\n",
    "y = word_counts['five_star']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to split a training and test sample\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Percentage accuracy:\n",
      "0.5001866666666667\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.49944\n",
      "\n",
      "Cross Validation:\n",
      "[0.50016666 0.5002     0.5002     0.5002     0.50016668]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12514\n",
      "           1       0.50      1.00      0.67     12486\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     25000\n",
      "   macro avg       0.25      0.50      0.33     25000\n",
      "weighted avg       0.25      0.50      0.33     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:02.997325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# How long will it take\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "# get rid of the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1e9, max_iter = 150)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Set Up Predictor\n",
    "ypred_lr = lr.predict(x_test)\n",
    "\n",
    "print('Train Percentage accuracy:')\n",
    "print(lr.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(lr.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(lr, x_train, y_train, cv = 5))\n",
    "\n",
    "auc = roc_auc_score(y_test, ypred_lr)\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_lr))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 41.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data:\n",
      "{'C': 1000000000.0, 'max_iter': 50, 'penalty': 'l1'}\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12514\n",
      "           1       0.50      1.00      0.67     12486\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     25000\n",
      "   macro avg       0.25      0.50      0.33     25000\n",
      "weighted avg       0.25      0.50      0.33     25000\n",
      "\n",
      "\n",
      "Duration: 0:44:48.785196\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "# get rid of the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Grid Search CV for decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#GridSearchCV for random forest \n",
    "param_grid = {'C':[1e9,.5,1,3], 'max_iter':[25,50,100], 'penalty':['l1','l2']}\n",
    "\n",
    "# Start the grid search again\n",
    "grid_DT = GridSearchCV(lr, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_DT.fit(x_train, y_train)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "# View the accuracy score\n",
    "print('Best score for data:')\n",
    "print(grid_DT.best_params_)\n",
    "\n",
    "# Set Up Predictor\n",
    "ypred_lr = lr.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_lr))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Logistic regression runs pretty poorly here. With almost no ability to predict anything other than the outcome variable and even then not very well.\n",
    "- I think the strictly binary nature of logistic regression is holding this model back a bit. With the data having a text focus, other models may be better equipped to predict on this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.6309866666666667\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.63052\n",
      "\n",
      "Cross Validation:\n",
      "[0.63522432 0.6282     0.631      0.6276     0.63044203]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59     12514\n",
      "           1       0.61      0.73      0.66     12486\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     25000\n",
      "   macro avg       0.64      0.63      0.63     25000\n",
      "weighted avg       0.64      0.63      0.63     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:03.053461\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train, y_train)\n",
    "# Set Up Predictor\n",
    "ypred_bnb = bnb.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(bnb.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(bnb.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(bnb, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_bnb))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Like I pointed out above with the logistic regression, a non-numerical focused model might work better on the data and sure enough naive bayes most certainly does.\n",
    "- While this does work better on the data, it has a lot of room for improvement. The precision for both variables is alright but the recall on the false outcomes is a bit worrying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.6060266666666667\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.56452\n",
      "\n",
      "Cross Validation:\n",
      "[0.56489567 0.5604     0.5582     0.55793333 0.55083672]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.46      0.51     12514\n",
      "           1       0.55      0.67      0.61     12486\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     25000\n",
      "   macro avg       0.57      0.56      0.56     25000\n",
      "weighted avg       0.57      0.56      0.56     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:29.342848\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(x_train, y_train)\n",
    "# Set Up Predictor\n",
    "ypred_knn = knn.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(knn.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(knn.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(knn, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_knn))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data:\n",
      "{'n_neighbors': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   54.0s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "# Grid Search CV for decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#GridSearchCV for random forest \n",
    "param_grid = {'n_neighbors':[15,30,50,100,150,300,500,750,1000]}\n",
    "\n",
    "# Start the grid search again\n",
    "grid_DT = GridSearchCV(knn, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_DT.fit(x_train, y_train)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "# View the accuracy score\n",
    "print('Best score for data:')\n",
    "print(grid_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.60756\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.60576\n",
      "\n",
      "Cross Validation:\n",
      "[0.61202586 0.6026     0.6062     0.60086667 0.60757384]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.62     12514\n",
      "           1       0.61      0.58      0.60     12486\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     25000\n",
      "   macro avg       0.61      0.61      0.61     25000\n",
      "weighted avg       0.61      0.61      0.61     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:26.728532\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=500)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Set Up Predictor\n",
    "ypred_knn = knn.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(knn.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(knn.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(knn, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_knn))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- KNN doesn't seem to really improve on Naive Bayes. It might be because of the generally large amount of features.\n",
    "- Running grid search CV and ultimately upping the amount of neighbors by a considerably amount helped reduce the amount of overfitting in the data.\n",
    "- All in all, after upping the amount of neighbors this model actually runs pretty well. The accuracy score isn't perfect but it runs very balanced without much overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.6025866666666667\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.5848\n",
      "\n",
      "Cross Validation:\n",
      "[0.58416106 0.576      0.5834     0.58533333 0.57957197]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.57      0.58     12514\n",
      "           1       0.58      0.60      0.59     12486\n",
      "\n",
      "   micro avg       0.58      0.58      0.58     25000\n",
      "   macro avg       0.58      0.58      0.58     25000\n",
      "weighted avg       0.58      0.58      0.58     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:01.711542\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "from sklearn import tree\n",
    "\n",
    "dec_tr = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=1,\n",
    "    max_depth=20,\n",
    "    random_state = 1337\n",
    ")\n",
    "\n",
    "dec_tr.fit(x_train, y_train)\n",
    "# Set Up Predictor\n",
    "ypred_dec_tr = dec_tr.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(dec_tr.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(dec_tr.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(dec_tr, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_dec_tr))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Similar to other models, the decision tree runs alright. With not quite the best score we've had so far but a pretty good balance between precision and recall on both outcomes.\n",
    "- In true form with decision trees, this model is showing a bit of overfitting on the data and I can only imagine it might get worse if run on a larger dataset of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.79724\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.70364\n",
      "\n",
      "Cross Validation:\n",
      "[0.70501967 0.70533333 0.69853333 0.70286667 0.69831322]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70     12514\n",
      "           1       0.70      0.71      0.70     12486\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     25000\n",
      "   macro avg       0.70      0.70      0.70     25000\n",
      "weighted avg       0.70      0.70      0.70     25000\n",
      "\n",
      "\n",
      "Duration: 0:53:43.909040\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier(loss='exponential', max_depth=10 , n_estimators=50 )\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "ypred_clf = clf.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(clf.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(clf.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(clf, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, ypred_clf))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- While this is our best performing model by far so far, using it in a production environment might be a bit of a risk given it looks like it is overfitting a slight bit.\n",
    "- The overfitting is unfortunate, as the scores are quite good. With a great balance between precision and recall scores. \n",
    "- The general performance of this model isn't ideal as well. Where a runtime of about 50 minutes isn't the worst possible outcome, it also isn't ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.6861866666666666\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.67524\n",
      "\n",
      "Cross Validation:\n",
      "[0.67748817 0.67373333 0.6774     0.67466667 0.67224482]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67     12514\n",
      "           1       0.67      0.69      0.68     12486\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     25000\n",
      "   macro avg       0.68      0.68      0.68     25000\n",
      "weighted avg       0.68      0.68      0.68     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:14.938187\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=50, max_depth=8)\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "ypred_rfc = rfc.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(rfc.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(rfc.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(rfc, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, ypred_rfc))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- This is probably our best performing model so far. Achieving a nearly 70% accuracy with very little signs of overfitting. \n",
    "- Random Forest seems like a pretty good option for this set of data. It has all of the benefits found on the decision tree but seems to fix the overfitting problem we were having.\n",
    "- The precision and recall scores for both outcomes here are fairly even and would perform reasonably well in a production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with Bayes, Gradient Boosted Decision Tree & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separating out the features\n",
    "X = word_counts[key_vals].values\n",
    "# Separating out the target\n",
    "y = word_counts['five_star'].values\n",
    "# Standardizing the features\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['pc1','pc2','pc3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_pc = pd.concat([principalDf, word_counts], axis = 1).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "X = amz_pc[['pc1','pc2','pc3']]\n",
    "# Separating out the target\n",
    "y = amz_pc['five_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to split a training and test sample\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.5767066666666667\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.57788\n",
      "\n",
      "Cross Validation:\n",
      "[0.57662822 0.57426667 0.57586667 0.57526667 0.58150543]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56     12514\n",
      "           1       0.57      0.63      0.60     12486\n",
      "\n",
      "   micro avg       0.58      0.58      0.58     25000\n",
      "   macro avg       0.58      0.58      0.58     25000\n",
      "weighted avg       0.58      0.58      0.58     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:00.180982\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train, y_train)\n",
    "# Set Up Predictor\n",
    "ypred_bnb = bnb.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(bnb.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(bnb.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(bnb, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_bnb))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.6444133333333333\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.60408\n",
      "\n",
      "Cross Validation:\n",
      "[0.60789281 0.6002     0.6058     0.59973333 0.60244016]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61     12514\n",
      "           1       0.61      0.59      0.60     12486\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     25000\n",
      "   macro avg       0.60      0.60      0.60     25000\n",
      "weighted avg       0.60      0.60      0.60     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:31.930119\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier(loss='exponential', max_depth=8 , n_estimators=50 )\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "ypred_clf = clf.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(clf.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(clf.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(clf, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, ypred_clf))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.61892\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.60464\n",
      "\n",
      "Cross Validation:\n",
      "[0.61049263 0.6016     0.60686667 0.60266667 0.60337356]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61     12514\n",
      "           1       0.61      0.58      0.59     12486\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     25000\n",
      "   macro avg       0.60      0.60      0.60     25000\n",
      "weighted avg       0.60      0.60      0.60     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:12.557639\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=50, max_depth=8)\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "ypred_rfc = rfc.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(rfc.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(rfc.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(rfc, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, ypred_rfc))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.70912\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.57836\n",
      "\n",
      "Cross Validation:\n",
      "[0.57922805 0.57393333 0.57026667 0.57033333 0.57563838]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59     12514\n",
      "           1       0.58      0.56      0.57     12486\n",
      "\n",
      "   micro avg       0.58      0.58      0.58     25000\n",
      "   macro avg       0.58      0.58      0.58     25000\n",
      "weighted avg       0.58      0.58      0.58     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:01.175464\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "from sklearn import tree\n",
    "\n",
    "dec_tr = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=1,\n",
    "    max_depth=20,\n",
    "    random_state = 1337\n",
    ")\n",
    "\n",
    "dec_tr.fit(x_train, y_train)\n",
    "# Set Up Predictor\n",
    "ypred_dec_tr = dec_tr.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(dec_tr.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(dec_tr.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(dec_tr, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_dec_tr))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.6296533333333333\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.5902\n",
      "\n",
      "Cross Validation:\n",
      "[0.59089394 0.58966667 0.58466667 0.58726667 0.5910394 ]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.64      0.61     12514\n",
      "           1       0.60      0.54      0.57     12486\n",
      "\n",
      "   micro avg       0.59      0.59      0.59     25000\n",
      "   macro avg       0.59      0.59      0.59     25000\n",
      "weighted avg       0.59      0.59      0.59     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:02.451482\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(x_train, y_train)\n",
    "# Set Up Predictor\n",
    "ypred_knn = knn.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(knn.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(knn.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(knn, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_knn))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data: {'n_neighbors': 700}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:  4.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV for decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#GridSearchCV for random forest \n",
    "param_grid = {'n_neighbors':[5,10,30,50,75,100,150,300,500,700,1000]}\n",
    "\n",
    "# Start the grid search again\n",
    "grid_DT = GridSearchCV(knn, param_grid, cv=5, verbose=1)\n",
    "\n",
    "grid_DT.fit(x_train, y_train)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "# View the accuracy score\n",
    "print('Best score for data:', grid_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Percentage accuracy:\n",
      "0.6072\n",
      "\n",
      "Test Percentage accuracy:\n",
      "0.6052\n",
      "\n",
      "Cross Validation:\n",
      "[0.61282581 0.6034     0.60646667 0.60046667 0.60677378]\n",
      "\n",
      "Area Under Curve:\n",
      "AUC: 0.500\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.62     12514\n",
      "           1       0.61      0.58      0.59     12486\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     25000\n",
      "   macro avg       0.61      0.61      0.60     25000\n",
      "weighted avg       0.61      0.61      0.60     25000\n",
      "\n",
      "\n",
      "Duration: 0:00:34.945774\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=700)\n",
    "knn.fit(x_train, y_train)\n",
    "# Set Up Predictor\n",
    "ypred_knn = knn.predict(x_test)\n",
    "\n",
    "print('\\nTrain Percentage accuracy:')\n",
    "print(knn.score(x_train, y_train))\n",
    "\n",
    "print('\\nTest Percentage accuracy:')\n",
    "print(knn.score(x_test, y_test))\n",
    "\n",
    "print('\\nCross Validation:')\n",
    "print(cross_val_score(knn, x_train, y_train, cv = 5))\n",
    "\n",
    "print('\\nArea Under Curve:')\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, ypred_knn))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Running PCA through all of the models helped speed up performance generally on just about all models but with the cost of some performance on just about all of them as well. I would only recommend going with the PCA'd versions if performance was a real issue. It specifically seemed to help a bout of overfitting on the KNN model but otherwise the benefits seemed to be only in the performance.\n",
    "\n",
    "After running all of the models, it is clear that Random Forest is the clear choice for moving forward into production with. It's reliance on the decision based features of the decision tree gives it all the benefits of the decision tree without the overfitting issues. It seems to play very well with the text based nature of the dataset or at least the binary nature of almost all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
